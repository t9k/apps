# Default values for vllm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: vllm/vllm-openai
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v0.4.2"

model:
  # 模型以该名称被部署
  name: ""

  volume:
    storageClass: ""
    size: 32Gi
    accessModes:
      - ReadWriteOnce
    existingClaim: ""
    subPath: ""

  # 模型来源
  # 应为 ""、"huggingface"、"git" 或 "s3"，"" 表示不下载
  source: ""
  huggingface:
    # 模型的 Hugging Face ID，例如 "meta-llama/Meta-Llama-3-8B"
    id: ""
    # 下载的文件列表，例如 "README.md,tokenizer.json,tokenizer_config.json"，默认为所有文件
    files: ""
    # 引用 Secret 的键 token 的值作为 Hugging Face token
    existingSecret: ""
  git:
    # Git 仓库路径
    url: ""
    # 分支、标签或 commit
    ref: ""
    # 引用 Secret 的键 token 的值作为 Git token
    existingSecret: ""
  s3:
    # S3 路径
    url: ""
    # 引用 s3-env 类型的 Secret 的键值
    existingSecret: ""

t9k:
  queue: ""

service:
  port: 8000

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  limits:
    cpu: 4
    memory: 64Gi
    nvidia.com/gpu: 1

env:
  # HTTP 和 HTTPS 代理
  - name: HTTP_PROXY
    value: ""
  - name: HTTPS_PROXY
    value: ""
