apiVersion: app.tensorstack.dev/v1beta1
kind: Template
metadata:
  name: ollama
  displayName: Ollama
  categories: ["AI"]
  description: "Ollama 提供本地使用 LLM 的解决方案。"
  icon: "file://$APP_DIR/icon.png"
template:
  helm:
    repo: "oci://docker.io/t9kpublic"
    # repo: "https://t9k.github.io/apps/"
    chart: "ollama"
    versions:
    - version: 0.54.4
      config: "file://$APP_DIR/configs/v2/v0_54_4.yaml"
      urls: []
      readinessProbe:
        resources:
        - group: apps
          version: v1
          resource: deployments
          name: "{{ .Release.Name }}"
          currentStatus: "{{- range .status.conditions }}{{- if eq .type \"Available\" }}{{- .status }}{{- end }}{{- end }}"
          desiredStatus: "True"
      dependencies: {}
