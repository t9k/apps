apiVersion: app.tensorstack.dev/v1beta1
kind: Template
metadata:
  name: vllm-llama3
  displayName: "vLLM (Llama 3)"
  categories: ["AI"]
  description: "使用 vLLM 部署 Llama 3 系列模型。"
  icon: "file://$APP_DIR/icon.svg"
template:
  helm:
    repo: oci://registry.dockermirror.com/t9kpublic
    # repo: oci://registry.dockermirror.com/t9kpublic
    chart: "vllm-llama3"
    versions:
    - version: 0.1.3
      urls: []
      readinessProbe:
        resources:
        - group: tensorstack.dev
          version: v1beta1
          resource: simplemlservices
          name: "{{ .Release.Name }}"
          currentStatus: "{{- range .status.conditions }}{{- if eq .type \"Ready\" }}{{- .status }}{{- end }}{{- end }}"
          desiredStatus: "True"
      dependencies: {}
