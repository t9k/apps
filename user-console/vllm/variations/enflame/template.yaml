apiVersion: app.tensorstack.dev/v1beta2
kind: Template
metadata:
  name: vllm-enflame
  displayName: "vLLM (Enflame GCU)"
  categories: ["AI"]
  description: "vLLM 是一个高吞吐量和内存高效的 LLM 推理和服务引擎。"
  icon:
    url: "file://$APP_DIR/icon.png"
template:
  versions:
  - version: 0.3.3
    chart:
      repo: "oci://registry.qy.t9kcloud.cn/t9kcharts"
      name: "vllm-enflame"
      version: 0.3.3
    pausable: false
    config: "file://$APP_DIR/configs/v0_3_3.yaml"
    urls: []
    readinessProbe:
      resources:
      - group: tensorstack.dev
        version: v1beta1
        resource: mlservices
        name: "{{ .Release.Name }}"
        currentStatus: "{{- range .status.conditions }}{{- if eq .type \"Ready\" }}{{- .status }}{{- end }}{{- end }}"
        desiredStatus: "True"
    dependencies:
      crds:
      - group: tensorstack.dev
        version: v1beta1
        resource: mlservices
      - group: tensorstack.dev
        version: v1beta1
        resource: datacubes
