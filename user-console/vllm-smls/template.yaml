apiVersion: app.tensorstack.dev/v1beta1
kind: Template
metadata:
  name: vllm-smls
  displayName: vLLM
  categories: ["AI"]
  description: "vLLM 是一个用于大语言模型的高吞吐量和内存高效的推理和服务引擎。"
  icon: "file://$APP_DIR/icon.png"
template:
  helm:
    repo: "oci://docker.io/t9kpublic"
    chart: "vllm-smls"
    versions:
    - version: 0.1.2
      urls: []
      # readinessProbe:
      #   resources:
      #   - group: apps
      #     version: v1
      #     resource: deployments
      #     name: terminal-{{ .Release.Name }}
      #     currentStatus: "{{- range .status.conditions }}{{- if eq .type \"Available\" }}{{- .status }}{{- end }}{{- end }}"
      #     desiredStatus: "True"
      dependences: {}
